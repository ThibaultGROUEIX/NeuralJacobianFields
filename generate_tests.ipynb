{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Coordinate MLP (Tutte cutting)\n",
    "basestr = [\"--experiment_type\", \"DEFAULT\", \"--size_train\", \"1\", \"--size_test\", \"1\", \"--epochs\", \"10000\",\n",
    "             \"--val_interval\", \"20\", \"--data_file\", \"cylinder.json\", \"--align_2D\", \"--xp_type\", \"uv\", \"--gpu_strategy\", \"ddp\",\n",
    "              \"--n_gpu\", \"1\", \"--no_poisson\", \"--identity\", \"--initjinput\", \"--noencoder\",\n",
    "              \"--lossdistortion\", \"dirichlet\", \"--projectname\", \"coarsetutte\", \"--lr\", \"1e-5\",\n",
    "              \"--targets_per_batch\", \"16\", \"--workers\", \"1\", \"--outputdir\", \"./outputs/learning/coarse_tutte\",\n",
    "              \"--accumulate_grad_batches\", \"1\", \"--opttrans\", \"--min_cuts\", \"1\", \"--max_cuts\", \"6\",\n",
    "              \"--lossgradientstitching\", \"l2\",\n",
    "              \"--top_k_eig\", \"40\"]\n",
    "\n",
    "basestr = \"python ./training_scripts/train.py \" + ' '.join(basestr)\n",
    "inits = ['tutte']\n",
    "datadirs = ['coarsecylinder', 'coarsecylinder_nocut']\n",
    "lrs = ['1e-5']\n",
    "\n",
    "f = open(\"./slurm/cylinder_coarse_tutte\", 'w')\n",
    "for data in datadirs: \n",
    "    for init in inits:\n",
    "        expname = f\"coordmlp_{data}_init{init}\"\n",
    "        expstr = basestr + f\" --init {init} --ninit -1 --root_dir_train ./data/{data} --root_dir_test ./data/{data} --expname {expname}\"\n",
    "        f.write(expstr + \"\\n\")\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dense MLP\n",
    "## data type \n",
    "## stitching type \n",
    "## global rotation sampling/random/basis sampling \n",
    "basestr = [\"--experiment_type\", \"DEFAULT\", \"--size_train\", \"1\", \"--size_test\", \"1\", \"--epochs\", \"10000\",\n",
    "             \"--val_interval\", \"20\", \"--data_file\", \"cylinder.json\", \"--align_2D\", \"--xp_type\", \"uv\", \"--gpu_strategy\", \"ddp\",\n",
    "              \"--n_gpu\", \"1\", \"--no_poisson\", \"--identity\", \"--initjinput\", \"--noencoder\",\n",
    "              \"--lossdistortion\", \"dirichlet\", \"--projectname\", \"dense\", \"--lr\", \"1e-5\",\n",
    "              \"--targets_per_batch\", \"16\", \"--workers\", \"1\", \"--outputdir\", \"./outputs/dense_v2\",\n",
    "              \"--accumulate_grad_batches\", \"1\", \"--opttrans\",\n",
    "              \"--dense\", \"input\", \"--lossgradientstitching\", \"l2\",\n",
    "              \"--top_k_eig\", \"40\"]\n",
    "\n",
    "basestr = \"python ./training_scripts/train.py \" + ' '.join(basestr)\n",
    "inits = ['isometric']\n",
    "basistypes = ['rot', 'basis', 'global']\n",
    "gradclips = [True, False]\n",
    "datadirs = ['coarsecylinder', 'coarsecylinder_nocut']\n",
    "lrs = ['1e-5']\n",
    "\n",
    "f = open(\"./slurm/cylinder_dense\", 'w')\n",
    "for data in datadirs: \n",
    "    for init in inits:\n",
    "        for basis in basistypes: \n",
    "            expname = f\"{data}_init{init}_basis{basis}\"\n",
    "            expstr = basestr + f\" --init {init} --ninit -1 --root_dir_train ./data/{data} --root_dir_test ./data/{data} --expname {expname}\"\n",
    "            expstr += f\" --basistype {basis}\"\n",
    "            f.write(expstr + \"\\n\")\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Coordinate MLP\n",
    "## data type \n",
    "## stitching type \n",
    "## global rotation sampling/random/basis sampling \n",
    "basestr = [\"--experiment_type\", \"DEFAULT\", \"--size_train\", \"1\", \"--size_test\", \"1\", \"--epochs\", \"10000\",\n",
    "             \"--val_interval\", \"20\", \"--data_file\", \"cylinder.json\", \"--align_2D\", \"--xp_type\", \"uv\", \"--gpu_strategy\", \"ddp\",\n",
    "              \"--n_gpu\", \"1\", \"--no_poisson\", \"--identity\", \"--initjinput\", \"--noencoder\",\n",
    "              \"--lossdistortion\", \"dirichlet\", \"--projectname\", \"dense\", \"--lr\", \"1e-5\",\n",
    "              \"--targets_per_batch\", \"16\", \"--workers\", \"1\", \"--outputdir\", \"./outputs/coordmlp\",\n",
    "              \"--accumulate_grad_batches\", \"1\", \"--opttrans\",\n",
    "              \"--lossgradientstitching\", \"l2\",\n",
    "              \"--top_k_eig\", \"40\"]\n",
    "\n",
    "basestr = \"python ./training_scripts/train.py \" + ' '.join(basestr)\n",
    "inits = ['isometric']\n",
    "basistypes = ['rot', 'basis', 'global']\n",
    "gradclips = [True, False]\n",
    "datadirs = ['coarsecylinder', 'coarsecylinder_nocut']\n",
    "lrs = ['1e-5']\n",
    "\n",
    "f = open(\"./slurm/cylinder_coarse\", 'w')\n",
    "for data in datadirs: \n",
    "    for init in inits:\n",
    "        for basis in basistypes: \n",
    "            expname = f\"coordmlp_{data}_init{init}_basis{basis}\"\n",
    "            expstr = basestr + f\" --init {init} --ninit -1 --root_dir_train ./data/{data} --root_dir_test ./data/{data} --expname {expname}\"\n",
    "            expstr += f\" --basistype {basis}\"\n",
    "            f.write(expstr + \"\\n\")\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Hyperparam search: neural optimization w/ initj input\n",
    "## - distortion loss: arap/dirichlet \n",
    "## - initialization: tutte, isometric \n",
    "## - stitchloss schedule: T/F (tutte: 0->1, isometric: 1->2)\n",
    "## - l0relaxation + schedule: T/F\n",
    "\n",
    "basestr = [\"--experiment_type\", \"DEFAULT\", \"--size_train\", \"1\", \"--size_test\", \"1\", \"--epochs\", \"20000\",\n",
    "             \"--val_interval\", \"20\", \"--data_file\", \"cylinder.json\", \"--align_2D\", \"--xp_type\", \"uv\", \"--gpu_strategy\", \"ddp\",\n",
    "              \"--n_gpu\", \"1\", \"--no_poisson\", \"--identity\", \"--lr\", \"1e-5\", \"--ninit\", \"1\", \"--initjinput\",\n",
    "              \"--targets_per_batch\", \"16\", \"--workers\", \"8\", \"--outputdir\", \"./outputs/neuralopt\",\n",
    "              \"--accumulate_grad_batches\", \"1\", \"--opttrans\"]\n",
    "basestr = \"python ./training_scripts/train.py \" + ' '.join(basestr)\n",
    "inits = ['isometric', 'tutte']\n",
    "datadirs = ['cylinder', 'cylinder_nocut']\n",
    "distortions = ['dirichlet', 'arap']\n",
    "stitchschedules = [True, False]\n",
    "l0relaxes = [True, False]\n",
    "\n",
    "f = open(\"slurm/cylinder_neuralopt\", 'w')\n",
    "for data in datadirs: \n",
    "    for distortion in distortions: \n",
    "        for init in inits:\n",
    "            for stitchschedule in stitchschedules:\n",
    "                for l0 in l0relaxes:\n",
    "                    expname = f\"{data}_dist{distortion}_init{init}_stitchsched{stitchschedule}_l0{l0}\"\n",
    "                    expstr = basestr + f\" --init {init} --lossgradientstitching l2 --root_dir_train ./data/{data} --root_dir_test ./data/{data} --expname {expname}\"\n",
    "                    expstr += f\" --lossdistortion {distortion}\"\n",
    "                    if stitchschedule: \n",
    "                        if init == \"isometric\":\n",
    "                            expstr += f\" --stitchloss_schedule linear --stitchlossweight_min 1 --stitchlossweight_max 2\"\n",
    "                        if init == \"tutte\":\n",
    "                            expstr += f\" --stitchloss_schedule linear --stitchlossweight_min 0 --stitchlossweight_max 1\"\n",
    "                    if l0: \n",
    "                        expstr += f\" --seploss_schedule --stitchrelax\"\n",
    "                    f.write(expstr + \"\\n\")\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple init learning experiment  \n",
    "basestr = [\"--experiment_type\", \"DEFAULT\", \"--size_train\", \"1\", \"--size_test\", \"1\", \"--epochs\", \"10000\",\n",
    "             \"--val_interval\", \"50\", \"--data_file\", \"cylinder.json\", \"--align_2D\", \"--xp_type\", \"uv\", \"--gpu_strategy\", \"ddp\",\n",
    "              \"--n_gpu\", \"1\", \"--no_poisson\", \"--identity\", \"--lr\", \"1e-5\", \"--workers\", \"8\", \"--opttrans\",\n",
    "              \"--lossdistortion\", \"dirichlet\", \"--targets_per_batch\", \"16\", \"--cuteps\", \"0.5\",  \n",
    "              \"--accumulate_grad_batches\", \"1\", \"--initjinput\", \"--outputdir\", \"outputs/learning\"]\n",
    "\n",
    "basestr = \"python ./training_scripts/train.py \" + ' '.join(basestr)\n",
    "inits = ['isometric']\n",
    "losses = [None, 'l2']\n",
    "basistypes = ['basis', 'rot']\n",
    "# ninits = [1,2,5,10,20,100]\n",
    "ninit_to_ratio = {1:1, 2:1, 5:1, 10: 0.2, 20: 0.1, 100: 0.1}\n",
    "datadirs = ['cylinder', 'cylinder_nocut']\n",
    "\n",
    "f = open(\"slurm/cylinder_n\", 'w')\n",
    "for data in datadirs: \n",
    "    for init in inits:\n",
    "        for loss in losses:\n",
    "            for basis in basistypes: \n",
    "                expname = f\"{data}_init{init}_loss{loss}_basis{basis}\"\n",
    "                expstr = basestr + f\" --init {init} --ninit -1 --root_dir_train ./data/{data} --root_dir_test ./data/{data} --expname {expname}\"\n",
    "                expstr += f\" --basistype {basis}\"\n",
    "                # expstr += f\" --valrenderratio {ninit_to_ratio[ninit]}\"\n",
    "                if loss:\n",
    "                    expstr += f\" --lossgradientstitching {loss}\"\n",
    "                else:\n",
    "                    expstr += f\" --lossedgeseparation\"\n",
    "                f.write(expstr + \"\\n\")\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient stitching experiments \n",
    "basestr = [\"--experiment_type\", \"DEFAULT\", \"--size_train\", \"1\", \"--size_test\", \"1\", \"--epochs\", \"3000\",\n",
    "             \"--val_interval\", \"20\", \"--data_file\", \"cylinder.json\", \"--align_2D\", \"--xp_type\", \"uv\", \"--gpu_strategy\", \"ddp\",\n",
    "              \"--n_gpu\", \"1\", \"--no_poisson\", \"--identity\", \"--lr\", \"0.0001\",\n",
    "              \"--targets_per_batch\", \"16\",\n",
    "              \"--accumulate_grad_batches\", \"1\"]\n",
    "basestr = \"python ./training_scripts/train.py \" + ' '.join(basestr)\n",
    "# ffts = [True, False]\n",
    "inits = ['isometric', 'tutte']\n",
    "losses = ['l2']\n",
    "datadirs = ['cylinder', 'cylinder_nocut']\n",
    "distortions = ['dirichlet', 'edge']\n",
    "\n",
    "f = open(\"slurm/cylinder_grad_exps\", 'w')\n",
    "for data in datadirs: \n",
    "    for distortion in distortions: \n",
    "        for init in inits:\n",
    "            for loss in losses:\n",
    "                expname = f\"{data}_dist{distortion}_init{init}_loss{loss}\"\n",
    "                expstr = basestr + f\" --init {init} --lossgradientstitching {loss} --root_dir_train ./data/{data} --root_dir_test ./data/{data} --expname {expname}\"\n",
    "                # if fft:\n",
    "                #     expstr += \" --fft --fft_dim 256\"\n",
    "                expstr += f\" --lossdistortion {distortion}\"\n",
    "                f.write(expstr + \"\\n\")\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flat direct optimization experiments\n",
    "basestr = \"python directopt.py\"\n",
    "\n",
    "datadirs = ['cyl', 'cylnocut']\n",
    "inits = ['isom']\n",
    "# anneals = [True, False]\n",
    "grads = [None, 'l2', 'split']\n",
    "\n",
    "f = open(\"slurm/directopt_tests_v2\", 'w')\n",
    "for data in datadirs:\n",
    "    for init in inits:\n",
    "        for grad in grads:\n",
    "            # Don't anneal if grad\n",
    "            if anneal and grad is not None: \n",
    "                continue \n",
    "            expname = f\"dopt_v2_data{data}_init{init}_grad{grad}\"\n",
    "            expstr = basestr + f\" --vs ./scratch/data/{data}_vs.pt --fs ./scratch/data/{data}_fs.pt --init ./scratch/data/{data}_{init}.pt --savedir ./scratch/{expname}\"\n",
    "            if grad:\n",
    "                expstr += f\" --grad {grad}\"\n",
    "            f.write(expstr + \"\\n\")\n",
    "f.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flat sanity check experiments\n",
    "basestr = [\"--experiment_type\", \"DEFAULT\", \"--size_train\", \"1\", \"--size_test\", \"1\", \"--epochs\", \"2000\",\n",
    "             \"--val_interval\", \"20\", \"--data_file\", \"cylinder.json\", \"--align_2D\", \"--xp_type\", \"uv\", \"--gpu_strategy\", \"ddp\",\n",
    "              \"--n_gpu\", \"1\", \"--no_poisson\", \"--identity\", \"--lr\", \"1e-5\",\n",
    "              \"--layer_normalization\", \"FLATTEN\",\n",
    "              \"--lossdistortion\", \"dirichlet\", \"--targets_per_batch\", \"16\",\n",
    "              \"--accumulate_grad_batches\", \"1\"]\n",
    "basestr = \"python ./training_scripts/train.py \" + ' '.join(basestr)\n",
    "\n",
    "datadirs = ['cylinder', 'cylinder_nocut']\n",
    "inits = ['isometric', 'tutte']\n",
    "sepdeltas = [0.1]\n",
    "# schedules = [True, False]\n",
    "grads = [None, 'l2', 'split']\n",
    "\n",
    "f = open(\"slurm/cylinder_flat\", 'w')\n",
    "for data in datadirs:\n",
    "    for delta in sepdeltas:\n",
    "        for init in inits:\n",
    "            for grad in grads:\n",
    "                expname = f\"flatcyl_sepd{delta}_data{data}_init{init}_grad{grad}\"\n",
    "                expstr = basestr + f\" --root_dir_train ./data/{data} --root_dir_test ./data/{data} --init {init} --seplossdelta {delta} --expname {expname}\"\n",
    "                if grad:\n",
    "                    expstr += f\" --lossgradientstitching {grad}\"\n",
    "                else: \n",
    "                    expstr += f\" --lossedgeseparation --seplossweight 1\"\n",
    "                f.write(expstr + \"\\n\")\n",
    "f.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basestr = [\"--root_dir_train\", \"./data/cylinder\", \"--root_dir_test\", \"./data/cylinder\",\n",
    "             \"--experiment_type\", \"DEFAULT\", \"--size_train\", \"1\", \"--size_test\", \"1\", \"--epochs\", \"8000\",\n",
    "             \"--val_interval\", \"20\", \"--data_file\", \"cylinder.json\", \"--align_2D\", \"--xp_type\", \"uv\", \"--gpu_strategy\", \"ddp\",\n",
    "              \"--n_gpu\", \"1\", \"--no_poisson\", \"--identity\", \"--lr\", \"0.005\",\n",
    "              \"--lossdistortion\", \"dirichlet\", \"--lossedgeseparation\", \"--seplossweight\", \"1\", \"--targets_per_batch\", \"16\",\n",
    "              \"--accumulate_grad_batches\", \"1\", \"--fft\", \"--fft_dim\", \"256\"]\n",
    "basestr = \"python ./training_scripts/train.py \" + ' '.join(basestr)\n",
    "sepdeltas = [0.01, 0.1, 0.5]\n",
    "seplosses = ['l1', 'mse']\n",
    "\n",
    "f = open(\"slurm/cylinder_exps\", 'w')\n",
    "for delta in sepdeltas:\n",
    "    for seploss in seplosses:\n",
    "        expname = f\"cylinder_sepd{delta}_sepl{seploss}\"\n",
    "        expstr = basestr + f\" --init isometric --eseploss {seploss} --seplossdelta {delta} --expname {expname}\"\n",
    "        f.write(expstr + \"\\n\")\n",
    "f.close() \n",
    "\n",
    "inits = ['isometric', 'tutte']\n",
    "f = open(\"slurm/cylinder_exps_v2\", 'w')\n",
    "for init in inits:\n",
    "    for seploss in seplosses:\n",
    "        expname = f\"cylinder_init{init}_sepl{seploss}\"\n",
    "        expstr = basestr + f\" --init {init} --eseploss {seploss} --expname {expname} --seploss_schedule --seplossdelta_min 0.001\"\n",
    "        f.write(expstr + \"\\n\")\n",
    "f.close() \n",
    "\n",
    "# Same for bunny\n",
    "basestr = [\"--root_dir_train\", \"./data/bunny\", \"--root_dir_test\", \"./data/bunny\",\n",
    "             \"--experiment_type\", \"DEFAULT\", \"--size_train\", \"1\", \"--size_test\", \"1\", \"--epochs\", \"8000\",\n",
    "             \"--val_interval\", \"20\", \"--data_file\", \"bunny.json\", \"--align_2D\", \"--xp_type\", \"uv\", \"--gpu_strategy\", \"ddp\",\n",
    "              \"--n_gpu\", \"1\", \"--no_poisson\", \"--identity\", \"--init\", \"isometric\", \"--lr\", \"0.005\",\n",
    "              \"--lossdistortion\", \"dirichlet\", \"--lossedgeseparation\", \"--seplossweight\", \"1\", \"--targets_per_batch\", \"16\",\n",
    "              \"--accumulate_grad_batches\", \"1\"]\n",
    "basestr = \"python ./training_scripts/train.py \" + ' '.join(basestr)\n",
    "sepdeltas = [0.01, 0.1, 0.5]\n",
    "seplosses = ['l1', 'mse']\n",
    "\n",
    "f = open(\"slurm/bunny_exps\", 'w')\n",
    "for delta in sepdeltas:\n",
    "    for seploss in seplosses:\n",
    "        expname = f\"bunny_sepd{delta}_sepl{seploss}\"\n",
    "        expstr = basestr + f\" --eseploss {seploss} --seplossdelta {delta} --expname {expname}\"\n",
    "        f.write(expstr + \"\\n\")\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--root_dir_train ./data/cylinder --root_dir_test ./data/cylinder --expname Debug --experiment_type DEFAULT --size_train 1 --size_test 1 --epochs 5000 --val_interval 20 --data_file cylinder.json --align_2D --xp_type uv --gpu_strategy ddp --n_gpu 1 --no_poisson --lossdistortion dirichlet --identity --init isometric --lossedgeseparation --seplossdelta 0.5 --seplossweight 1 --targets_per_batch 16 --accumulate_grad_batches 1\n"
     ]
    }
   ],
   "source": [
    "argstr = \"\"\"--root_dir_train ./data/cylinder --root_dir_test ./data/cylinder --expname Debug --experiment_type DEFAULT \n",
    "        --size_train 1 --size_test 1 --epochs 5000 --val_interval 20 --data_file cylinder.json --align_2D --xp_type uv \n",
    "        --gpu_strategy ddp --n_gpu 1 --no_poisson --lossdistortion dirichlet --identity --init isometric --lossedgeseparation \n",
    "        --seplossdelta 0.1 --seplossweight 1 --targets_per_batch 16 --accumulate_grad_batches 1\"\"\"\n",
    "print(\" \".join(argstr.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6aba07be85c1c9a493ebf9e24b9687878e9ec4d611dd45a562119e3e9c612ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
